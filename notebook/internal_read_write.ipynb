{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to built-in datasources\n",
    "\n",
    "Read from CSV and create temp view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "sc = SparkContext(\"local\", \"Internal read/write\")\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('Internal read/write')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "csv_file = '../datasets/departuredelays.csv'\n",
    "df = (spark\n",
    "      .read\n",
    "      .format('csv')\n",
    "      .option('inferSchema', 'true')\n",
    "      .option('header', 'true')\n",
    "      .load(csv_file))\n",
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform some queries on temp table:\n",
    "\n",
    "* using Spark SQL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+\n",
      "|origin|destination|distance|\n",
      "+------+-----------+--------+\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "|   HNL|        JFK|    4330|\n",
      "+------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+------+-----------+--------+\n",
      "|   date|origin|destination|distance|\n",
      "+-------+------+-----------+--------+\n",
      "|2190925|   SFO|        ORD|    1604|\n",
      "|1031755|   SFO|        ORD|    1604|\n",
      "|1022330|   SFO|        ORD|    1604|\n",
      "|1051205|   SFO|        ORD|    1604|\n",
      "|1190925|   SFO|        ORD|    1604|\n",
      "|2171115|   SFO|        ORD|    1604|\n",
      "|1071040|   SFO|        ORD|    1604|\n",
      "|1051550|   SFO|        ORD|    1604|\n",
      "|3120730|   SFO|        ORD|    1604|\n",
      "|1261104|   SFO|        ORD|    1604|\n",
      "+-------+------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT origin, destination, distance\n",
    "FROM us_delay_flights_tbl\n",
    "WHERE distance > 1000\n",
    "ORDER BY distance DESC\"\"\").show(10)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT date, origin, destination, distance\n",
    "FROM us_delay_flights_tbl\n",
    "WHERE delay > 120 AND ORIGIN = 'SFO' AND DESTINATION = 'ORD'\n",
    "ORDER BY delay DESC\"\"\").show(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+--------+----------------+\n",
      "|   date|origin|destination|distance|   Flight_Delays|\n",
      "+-------+------+-----------+--------+----------------+\n",
      "|2190925|   SFO|        ORD|    1604|Very Long Delays|\n",
      "|1031755|   SFO|        ORD|    1604|Very Long Delays|\n",
      "|1022330|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1051205|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1190925|   SFO|        ORD|    1604|     Long Delays|\n",
      "|2171115|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1071040|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1051550|   SFO|        ORD|    1604|     Long Delays|\n",
      "|3120730|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1261104|   SFO|        ORD|    1604|     Long Delays|\n",
      "+-------+------+-----------+--------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT date, origin, destination, distance,\n",
    "CASE\n",
    "  WHEN delay > 360 THEN 'Very Long Delays'\n",
    "  WHEN delay > 120 AND delay < 360 THEN 'Long Delays'\n",
    "  WHEN delay > 60 AND delay < 120 THEN 'Short Delays'\n",
    "  WHEN delay > 0 and delay < 60  THEN  'Tolerable Delays'\n",
    "  WHEN delay = 0 THEN 'No Delays'\n",
    "  ELSE 'Early'\n",
    "END AS Flight_Delays\n",
    "FROM us_delay_flights_tbl\n",
    "WHERE delay > 120 AND ORIGIN = 'SFO' AND DESTINATION = 'ORD'\n",
    "ORDER BY delay DESC\"\"\").show(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* using Spark DataFrame API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+\n",
      "|origin|destination|distance|\n",
      "+------+-----------+--------+\n",
      "|   SFO|        ORD|    1604|\n",
      "|   PDX|        DFW|    1404|\n",
      "|   EGE|        JFK|    1517|\n",
      "|   ONT|        DFW|    1033|\n",
      "|   CMH|        LAX|    1734|\n",
      "|   AUS|        LAX|    1079|\n",
      "|   IAD|        DFW|    1018|\n",
      "|   LAS|        MIA|    1889|\n",
      "|   FAT|        DFW|    1141|\n",
      "|   BOS|        MIA|    1093|\n",
      "+------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+------+-----------+--------+\n",
      "|   date|origin|destination|distance|\n",
      "+-------+------+-----------+--------+\n",
      "|2190925|   SFO|        ORD|    1604|\n",
      "|1031755|   SFO|        ORD|    1604|\n",
      "|1022330|   SFO|        ORD|    1604|\n",
      "|1051205|   SFO|        ORD|    1604|\n",
      "|1190925|   SFO|        ORD|    1604|\n",
      "|2171115|   SFO|        ORD|    1604|\n",
      "|1071040|   SFO|        ORD|    1604|\n",
      "|1051550|   SFO|        ORD|    1604|\n",
      "|3120730|   SFO|        ORD|    1604|\n",
      "|1261104|   SFO|        ORD|    1604|\n",
      "+-------+------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    " .select('origin', 'destination', 'distance')\n",
    " .where(F.col('distance') > 1000)\n",
    " .orderBy(F.col('delay').desc())\n",
    " .show(10))\n",
    "\n",
    "(df\n",
    " .select('date', 'origin', 'destination', 'distance')\n",
    " .where((F.col('delay') > 120)\n",
    "        & (F.col('origin')=='SFO')\n",
    "        & (F.col('destination')=='ORD'))\n",
    " .orderBy(F.col('delay').desc())\n",
    " .show(10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+--------+----------------+\n",
      "|   date|origin|destination|distance|   Flight_Delays|\n",
      "+-------+------+-----------+--------+----------------+\n",
      "|2190925|   SFO|        ORD|    1604|Very Long Delays|\n",
      "|1031755|   SFO|        ORD|    1604|Very Long Delays|\n",
      "|1022330|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1051205|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1190925|   SFO|        ORD|    1604|     Long Delays|\n",
      "|2171115|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1071040|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1051550|   SFO|        ORD|    1604|     Long Delays|\n",
      "|3120730|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1261104|   SFO|        ORD|    1604|     Long Delays|\n",
      "+-------+------+-----------+--------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "udf:  2.428698637  seconds\n",
      "+-------+------+-----------+--------+----------------+\n",
      "|   date|origin|destination|distance|   Flight_Delays|\n",
      "+-------+------+-----------+--------+----------------+\n",
      "|2190925|   SFO|        ORD|    1604|Very Long Delays|\n",
      "|1031755|   SFO|        ORD|    1604|Very Long Delays|\n",
      "|1022330|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1051205|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1190925|   SFO|        ORD|    1604|     Long Delays|\n",
      "|2171115|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1071040|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1051550|   SFO|        ORD|    1604|     Long Delays|\n",
      "|3120730|   SFO|        ORD|    1604|     Long Delays|\n",
      "|1261104|   SFO|        ORD|    1604|     Long Delays|\n",
      "+-------+------+-----------+--------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "pandas_udf:  2.3664525040000015  seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, pandas_udf\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def delay_classification(delay):\n",
    "    if delay > 360:\n",
    "        return 'Very Long Delays'\n",
    "    if 120 < delay < 360:\n",
    "        return 'Long Delays'\n",
    "    if 60 < delay < 120:\n",
    "        return 'Short Delays'\n",
    "    if 0 < delay < 60:\n",
    "        return 'Tolerable Delays'\n",
    "    if delay == 0:\n",
    "        return 'No Delays'\n",
    "    return 'Early'\n",
    "\n",
    "@pandas_udf('string')\n",
    "def pudf_delay_classification(delay: pd.Series) -> pd.Series:\n",
    "    return delay.apply(delay_classification)\n",
    "\n",
    "udf_delay_classification = udf(delay_classification)\n",
    "\n",
    "start = time.perf_counter()\n",
    "(df\n",
    " .select('date', 'origin', 'destination', 'distance',\n",
    "         udf_delay_classification(F.col('delay')).alias('Flight_Delays'))\n",
    " .where((F.col('delay') > 120)\n",
    "        & (F.col('origin')=='SFO')\n",
    "        & (F.col('destination')=='ORD'))\n",
    " .orderBy(F.col('delay').desc())\n",
    " .show(10))\n",
    "print('udf: ', time.perf_counter() - start, ' seconds')\n",
    "\n",
    "start = time.perf_counter()\n",
    "(df\n",
    " .select('date', 'origin', 'destination', 'distance',\n",
    "         pudf_delay_classification(F.col('delay')).alias('Flight_Delays'))\n",
    " .where((F.col('delay') > 120)\n",
    "        & (F.col('origin')=='SFO')\n",
    "        & (F.col('destination')=='ORD'))\n",
    " .orderBy(F.col('delay').desc())\n",
    " .show(10))\n",
    "print('pandas_udf: ', time.perf_counter() - start, ' seconds')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Managed and unmanaged tables\n",
    "\n",
    "Managed table\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|    6|     602|   ABE|        ATL|\n",
      "|01020600|   -8|     369|   ABE|        DTW|\n",
      "|01021245|   -2|     602|   ABE|        ATL|\n",
      "|01020605|   -4|     602|   ABE|        ATL|\n",
      "|01031245|   -4|     602|   ABE|        ATL|\n",
      "|01030605|    0|     602|   ABE|        ATL|\n",
      "|01041243|   10|     602|   ABE|        ATL|\n",
      "|01040605|   28|     602|   ABE|        ATL|\n",
      "|01051245|   88|     602|   ABE|        ATL|\n",
      "|01050605|    9|     602|   ABE|        ATL|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema=\"date STRING, delay INT, distance INT, origin STRING, destination STRING\"\n",
    "flights_df = spark.read.csv(csv_file, schema=schema, header=True)\n",
    "flights_df.write.saveAsTable(\n",
    "    \"managed_us_delay_flights_tbl\",\n",
    "    mode='ignore'\n",
    ")\n",
    "flights_df.show(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[date: string, delay: int, distance: int, origin: string, destination: string]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM managed_us_delay_flights_tbl\n",
    "LIMIT 10\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unmanaged table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noinspection SqlNoDataSourceInspection\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS us_delay_flights_tbl(date STRING, delay INT,\n",
    "distance INT, origin STRING, destination STRING)\n",
    "USING csv OPTIONS (PATH\n",
    "'{csv_file}')\n",
    "\"\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|    6|     602|   ABE|        ATL|\n",
      "|1020600|   -8|     369|   ABE|        DTW|\n",
      "|1021245|   -2|     602|   ABE|        ATL|\n",
      "|1020605|   -4|     602|   ABE|        ATL|\n",
      "|1031245|   -4|     602|   ABE|        ATL|\n",
      "|1030605|    0|     602|   ABE|        ATL|\n",
      "|1041243|   10|     602|   ABE|        ATL|\n",
      "|1040605|   28|     602|   ABE|        ATL|\n",
      "|1051245|   88|     602|   ABE|        ATL|\n",
      "|1050605|    9|     602|   ABE|        ATL|\n",
      "+-------+-----+--------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM us_delay_flights_tbl\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# or equivalently\n",
    "(flights_df\n",
    " .write\n",
    " #.option(\"path\", \"/tmp/us_flights_delay\")\n",
    " .saveAsTable(\"us_delay_flights_tbl\",\n",
    "              mode='overwrite',\n",
    "              path='/tmp/us_flights_delay'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating views\n",
    "Global temp view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|1011250|   55|   SFO|        JFK|\n",
      "|1012230|    0|   SFO|        JFK|\n",
      "|1010705|   -7|   SFO|        JFK|\n",
      "|1010620|   -3|   SFO|        MIA|\n",
      "|1010915|   -3|   SFO|        LAX|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE GLOBAL TEMP VIEW us_origin_airport_SFO_global_tmp_view AS\n",
    "SELECT date, delay, origin, destination\n",
    "FROM us_delay_flights_tbl\n",
    "WHERE origin = 'SFO'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM global_temp.us_origin_airport_SFO_global_tmp_view\n",
    "LIMIT 10\n",
    "\"\"\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already existed\n"
     ]
    }
   ],
   "source": [
    "# or equivalently\n",
    "df_sfo = spark.sql(\"\"\"\n",
    "SELECT date, delay, origin, destination\n",
    "FROM us_delay_flights_tbl WHERE origin = 'SFO'\"\"\")\n",
    "try:\n",
    "    df_sfo.createGlobalTempView('us_origin_airport_SFO_global_tmp_view')\n",
    "except:\n",
    "    print('Table already existed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Local (session-scoped) temp view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|1011250|   55|   SFO|        JFK|\n",
      "|1012230|    0|   SFO|        JFK|\n",
      "|1010705|   -7|   SFO|        JFK|\n",
      "|1010620|   -3|   SFO|        MIA|\n",
      "|1010915|   -3|   SFO|        LAX|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW us_origin_airport_SFO_tmp_view AS\n",
    "SELECT date, delay, origin, destination\n",
    "FROM us_delay_flights_tbl\n",
    "WHERE origin = 'SFO'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM us_origin_airport_SFO_tmp_view\n",
    "LIMIT 10\n",
    "\"\"\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already existed\n"
     ]
    }
   ],
   "source": [
    "# or equivalently\n",
    "df_sfo = spark.sql(\"\"\"\n",
    "SELECT date, delay, origin, destination\n",
    "FROM us_delay_flights_tbl WHERE origin = 'SFO'\"\"\")\n",
    "try:\n",
    "    df_sfo.createTempView('us_origin_airport_SFO_tmp_view')\n",
    "except:\n",
    "    print('Table already existed')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[Database(name='default', description='default database', locationUri='file:/Users/lap01195/Documents/random_code/spark/git/notebook/spark-warehouse')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()#%%\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[Table(name='managed_us_delay_flights_tbl', database='default', description=None, tableType='MANAGED', isTemporary=False),\n Table(name='us_delay_flights_tbl', database='default', description=None, tableType='EXTERNAL', isTemporary=False),\n Table(name='us_delay_flights_tbl', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n Table(name='us_origin_airport_sfo_tmp_view', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[Column(name='date', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n Column(name='delay', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n Column(name='distance', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n Column(name='origin', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n Column(name='destination', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"us_delay_flights_tbl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}