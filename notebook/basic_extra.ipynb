{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"Basic extra\")\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('Basic extra')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use DataFrame is more code-readable\n",
    "Create a dataset and compute average age for each name value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Brooke', 22.5), ('Denny', 31.0), ('Jules', 30.0), ('TD', 35.0)]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use RDD of tuples: (name, age)\n",
    "dataRDD = sc.parallelize(\n",
    "    [(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)]\n",
    ")\n",
    "agesRDD = (dataRDD\n",
    "           .map(lambda x: (x[0], (x[1], 1)))\n",
    "           .reduceByKey(lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
    "           .map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    "           )\n",
    "agesRDD.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, perform the same functionality with DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  Name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "| Denny|    31.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "dataRDD = spark.createDataFrame(\n",
    "    [(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)],\n",
    "    (\"name\", \"age\")\n",
    ")\n",
    "dataRDD.groupby(\"Name\").agg(avg(dataRDD.age)).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the schema programmatically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------+\n",
      "|author|title|       pages|\n",
      "+------+-----+------------+\n",
      "| Peter|   Mr| twitter.com|\n",
      "|  Mary|   Ms|facebook.com|\n",
      "|  John|   Mr| twitter.com|\n",
      "+------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([ # a table structure\n",
    "    StructField(\"author\", StringType(), False),\n",
    "    StructField(\"title\", StringType(), False),\n",
    "    StructField(\"pages\", StringType(), False)\n",
    "])\n",
    "data = [\n",
    "    (\"Peter\", \"Mr\", \"twitter.com\"),\n",
    "    (\"Mary\", \"Ms\", \"facebook.com\"),\n",
    "    (\"John\", \"Mr\", \"twitter.com\")\n",
    "]\n",
    "\n",
    "dataDF = spark.createDataFrame(\n",
    "    data,\n",
    "    schema\n",
    ")\n",
    "dataDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the schema by DDL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "schema = \"`Id` INT, `First` STRING, `Last` STRING, `Url` STRING,\\\n",
    "      `Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\"\n",
    "data = [\n",
    "    [1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "    [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "    [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "    [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"]],\n",
    "    [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "    [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]\n",
    "]\n",
    "authorDF = spark.createDataFrame(\n",
    "    data,\n",
    "    schema\n",
    ")\n",
    "authorDF.show()\n",
    "print(authorDF.printSchema())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Columns and Expressions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import expr, concat\n",
    "authorDF.select('Id', 'Hits', expr('Hits * 2')).show()\n",
    "authorDF.select('Id', 'Hits', authorDF.Hits * 2).show()\n",
    "authorDF.withColumn('Big Hitters', expr('Hits > 10000')).show()\n",
    "authorDF.withColumn('AuthorsId', concat(expr('First'), expr('Last'), expr('Id'))).show()\n",
    "# ==\n",
    "# authorDF.withColumn('AuthorsId', concat(authorDF.First, authorDF.Last, authorDF.Id)).show()\n",
    "authorDF.sort(authorDF.Hits.desc()).show(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| Id| Hits|(Hits * 2)|\n",
      "+---+-----+----------+\n",
      "|  1| 4535|      9070|\n",
      "|  2| 8908|     17816|\n",
      "|  3| 7659|     15318|\n",
      "|  4|10568|     21136|\n",
      "|  5|40578|     81156|\n",
      "|  6|25568|     51136|\n",
      "+---+-----+----------+\n",
      "\n",
      "+---+-----+----------+\n",
      "| Id| Hits|(Hits * 2)|\n",
      "+---+-----+----------+\n",
      "|  1| 4535|      9070|\n",
      "|  2| 8908|     17816|\n",
      "|  3| 7659|     15318|\n",
      "|  4|10568|     21136|\n",
      "|  5|40578|     81156|\n",
      "|  6|25568|     51136|\n",
      "+---+-----+----------+\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Big Hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|    AuthorsId|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|  JulesDamji1|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]| BrookeWenig2|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|    DennyLee3|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|TathagataDas4|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|MateiZaharia5|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|  ReynoldXin6|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "\n",
      "+---+-------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|  First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+-------+-------+-----------------+---------+-----+--------------------+\n",
      "|  5|  Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+-------+-------+-----------------+---------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rows\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|  Name|      Village|\n",
      "+------+-------------+\n",
      "|Naruto| Leaf village|\n",
      "|   Bee|Cloud village|\n",
      "+------+-------------+\n",
      "\n",
      "Naruto / Leaf village\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "rows = [\n",
    "    Row('Naruto', 'Leaf village'),\n",
    "    Row('Bee', 'Cloud village')\n",
    "]\n",
    "ninjaDF = spark.createDataFrame(rows, ('Name', 'Village'))\n",
    "ninjaDF.show()\n",
    "rows = ninjaDF.collect()\n",
    "row_0 = rows[0]\n",
    "print(row_0.Name, '/', row_0.Village)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataFrame API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- CallNumber: string (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: string (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: string (nullable = true)\n",
      " |-- ALSUnit: string (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: string (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: string (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "fire_path = '../datasets/sf-fire-calls.csv'\n",
    "fireDF = (spark\n",
    "          .read\n",
    "          .option(\"samplingRatio\", 0.01)\n",
    "          .option(\"header\", True)\n",
    "          .csv(fire_path))\n",
    "fireDF.show(5)\n",
    "print(fireDF.printSchema())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Projections and filters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------+\n",
      "|IncidentNumber|       AvailableDtTm|      CallType|\n",
      "+--------------+--------------------+--------------+\n",
      "|       2003235|01/11/2002 01:51:...|Structure Fire|\n",
      "|       2003250|01/11/2002 04:16:...|  Vehicle Fire|\n",
      "|       2003259|01/11/2002 06:01:...|        Alarms|\n",
      "+--------------+--------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------------------------------+\n",
      "|CallType                           |\n",
      "+-----------------------------------+\n",
      "|Elevator / Escalator Rescue        |\n",
      "|Marine Fire                        |\n",
      "|Aircraft Emergency                 |\n",
      "|Confined Space / Structure Collapse|\n",
      "|Administrative                     |\n",
      "|Alarms                             |\n",
      "|Odor (Strange / Unknown)           |\n",
      "|Citizen Assist / Service Call      |\n",
      "|HazMat                             |\n",
      "|Watercraft in Distress             |\n",
      "+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "few_fireDF = (fireDF\n",
    "              .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    "              .filter(col('CallType') != 'Medical Incident')\n",
    "              )\n",
    "few_fireDF.show(3)\n",
    "\n",
    "(fireDF\n",
    " .select('CallType')\n",
    " .where(col('CallType').isNotNull())\n",
    " .distinct()\n",
    " .show(10, False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add, Rename, Drop columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|6.25                 |\n",
      "|7.25                 |\n",
      "|11.916667            |\n",
      "|8.633333             |\n",
      "|95.28333             |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+\n",
      "|yearIncidentDate|\n",
      "+----------------+\n",
      "|            2000|\n",
      "|            2001|\n",
      "|            2002|\n",
      "|            2003|\n",
      "|            2004|\n",
      "|            2005|\n",
      "|            2006|\n",
      "|            2007|\n",
      "|            2008|\n",
      "|            2009|\n",
      "|            2010|\n",
      "|            2011|\n",
      "|            2012|\n",
      "|            2013|\n",
      "|            2014|\n",
      "|            2015|\n",
      "|            2016|\n",
      "|            2017|\n",
      "|            2018|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_fireDF = fireDF.withColumnRenamed('Delay', 'ResponseDelayedinMins')\n",
    "(new_fireDF\n",
    " .select('ResponseDelayedinMins')\n",
    " .where(col('ResponseDelayedinMins') > 5)\n",
    " .show(5, False)\n",
    " )\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, year, weekofyear\n",
    "new_fireDF = (new_fireDF\n",
    "              .withColumn('IncidentDate', to_timestamp(col('CallDate'), 'MM/dd/yyyy'))\n",
    "              .drop('CallDate')\n",
    "              .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    "              .drop('WatchDate')\n",
    "              .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "              .drop('AvailableDtTm')\n",
    "              )\n",
    "\n",
    "(new_fireDF\n",
    " .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    " .show(5, False))\n",
    "\n",
    "(new_fireDF\n",
    " .select(year(col('IncidentDate')).alias('yearIncidentDate'))\n",
    " .distinct()\n",
    " .sort(col('yearIncidentDate'))\n",
    " .show())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregations\n",
    "The most common types of fire calls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-------------+\n",
      "|CallType                     |CallTypeCount|\n",
      "+-----------------------------+-------------+\n",
      "|Medical Incident             |113794       |\n",
      "|Structure Fire               |23319        |\n",
      "|Alarms                       |19406        |\n",
      "|Traffic Collision            |7013         |\n",
      "|Citizen Assist / Service Call|2524         |\n",
      "+-----------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "(new_fireDF\n",
    " .select('CallType')\n",
    " .where(col('CallType').isNotNull())\n",
    " .groupBy('CallType')\n",
    " .agg(count('CallType').alias('CallTypeCount'))\n",
    " .orderBy(col('CallTypeCount').desc())\n",
    " .show(5, False)\n",
    " )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sum of alarms, the average response time, and the minimum and maximum response times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|      176170.0|        3.8923641541750413|               0.016666668|                      99.9|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "(new_fireDF\n",
    " .select(F.sum('NumAlarms'), F.avg('ResponseDelayedinMins'),\n",
    "         F.min('ResponseDelayedinMins'), F.max('ResponseDelayedinMins'))\n",
    " .show()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the different types of fire calls in 2018"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Explosion                    |\n",
      "|Vehicle Fire                 |\n",
      "|Suspicious Package           |\n",
      "|Other                        |\n",
      "|Outside Fire                 |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fireDF\n",
    " .where(year('IncidentDate')==2018)\n",
    " .select('CallType')\n",
    " .distinct()\n",
    " .show(10, False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What months within the year 2018 saw the highest number of fire calls?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|IncidentMonth|count|\n",
      "+-------------+-----+\n",
      "|           10| 1068|\n",
      "+-------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fireDF\n",
    " .select('IncidentDate')\n",
    " .where(year('IncidentDate')==2018)\n",
    " .groupBy(F.month('IncidentDate').alias('IncidentMonth'))\n",
    " .count()\n",
    " .orderBy(col('count').desc())\n",
    " .show(1)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neighborhood in San Francisco generated the most fire calls in 2018"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|Neighborhood                  |count|\n",
      "+------------------------------+-----+\n",
      "|Tenderloin                    |1393 |\n",
      "|South of Market               |1052 |\n",
      "|Mission                       |911  |\n",
      "|Financial District/South Beach|764  |\n",
      "|Bayview Hunters Point         |513  |\n",
      "+------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fireDF\n",
    " .select('Neighborhood', 'City', 'IncidentDate')\n",
    " .where((col('City')=='San Francisco') & (year('IncidentDate')==2018))\n",
    " .groupBy('Neighborhood')\n",
    " .count()\n",
    " .orderBy(col('count').desc())\n",
    " .show(5, truncate=False)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|Neighborhood                  |count|\n",
      "+------------------------------+-----+\n",
      "|Tenderloin                    |1393 |\n",
      "|South of Market               |1052 |\n",
      "|Mission                       |911  |\n",
      "|Financial District/South Beach|764  |\n",
      "|Bayview Hunters Point         |513  |\n",
      "+------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fireDF\n",
    " .select('Neighborhood', 'City', 'IncidentDate')\n",
    " .where(F.expr(\"City = 'San Francisco' and year(IncidentDate) = 2018\"))\n",
    " .groupBy('Neighborhood')\n",
    " .count()\n",
    " .orderBy(col('count').desc())\n",
    " .show(5, truncate=False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neighborhoods had the worst response times to fire calls in 2018"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------------+\n",
      "|Neighborhood         |MaxResponseDelayedinMins|\n",
      "+---------------------+------------------------+\n",
      "|South of Market      |94.71667                |\n",
      "|Bayview Hunters Point|92.816666               |\n",
      "|Inner Richmond       |90.433334               |\n",
      "|Russian Hill         |9.983334                |\n",
      "|Mission              |9.95                    |\n",
      "+---------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fireDF\n",
    ".select('Neighborhood', 'ResponseDelayedinMins', 'IncidentDate')\n",
    ".where(year(F.col('IncidentDate'))==2018)\n",
    ".groupBy('Neighborhood')\n",
    ".agg(F.max(F.col('ResponseDelayedinMins')).alias('MaxResponseDelayedinMins'))\n",
    ".orderBy('MaxResponseDelayedinMins', ascending=False)\n",
    ".show(5, truncate=False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Week in the year in 2018 had the most fire calls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|week|count|\n",
      "+----+-----+\n",
      "|40  |3645 |\n",
      "|35  |3549 |\n",
      "|38  |3548 |\n",
      "|44  |3546 |\n",
      "|20  |3519 |\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fireDF\n",
    " .select(weekofyear(F.col('IncidentDate')).alias('week'))\n",
    " .groupBy('week')\n",
    " .count()\n",
    " .orderBy('count', ascending=False)\n",
    " .show(5, truncate=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Is there a correlation between neighborhood, zip code, and number of fire calls?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|pValues|degreesOfFreedom|          statistics|\n",
      "+-------+----------------+--------------------+\n",
      "|  [0.0]|          [1066]|[2730627.6506358217]|\n",
      "+-------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "stat_DF = (new_fireDF\n",
    "           .select('Neighborhood', 'Zipcode')\n",
    "           .where(F.col('Neighborhood').isNotNull() & (F.col('Zipcode').isNotNull()))\n",
    "           )\n",
    "\n",
    "str_indexer = StringIndexer(inputCols=['Neighborhood', 'Zipcode'],\n",
    "                            outputCols=['NeighborhoodIndex', 'ZipcodeIndex'])\n",
    "vec_assembler = VectorAssembler(inputCols=['ZipcodeIndex'],\n",
    "                                outputCol='ZipcodeVector')\n",
    "transformed_DF = (vec_assembler.transform(str_indexer\n",
    "                        .fit(stat_DF)\n",
    "                        .transform(stat_DF))\n",
    ").select(F.col('NeighborhoodIndex'), 'ZipcodeVector')\n",
    "\n",
    "test_result = ChiSquareTest.test(transformed_DF,\n",
    "                   featuresCol='ZipcodeVector',\n",
    "                   labelCol='NeighborhoodIndex')\n",
    "test_result.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`pValues = 0.0` => significant."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}